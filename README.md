# Awesome-Multimodal-Agents

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of multimodal AI agents and related resources. Focuses on systems that combine multiple input modalities (text, vision, speech, etc.) and demonstrate agentic capabilities like reasoning, tool use, and environment interaction.

## Contents
- [Core Concepts](#core-concepts)
- [Agent Frameworks](#agent-frameworks)
- [Research Papers](#papers)
  - [Surveys & Overviews](#surveys--overviews)
  - [Models & Architectures](#models--architectures)
  - [Tools & Agent Learning](#tools--agent-learning)
  - [RAG (Retrieval-Augmented Generation)](#rag-retrieval-augmented-generation)
  - [Agent Learning & Optimization](#agent-learning--optimization)
  - [Vision-Language Understanding](#vision-language-understanding)
  - [Event-based Processing](#event-based-processing)
- [Tools & Libraries](#tools--libraries)
- [Tutorials & Courses](#tutorials--courses)
- [Contributing](#contributing)

[Previous sections remain unchanged until Research Papers]

## Papers

### Surveys & Overviews
[Previous content remains unchanged]

### Models & Architectures
[Previous content remains unchanged]

### Tools & Agent Learning
[Previous content remains unchanged]

### RAG (Retrieval-Augmented Generation)
[Previous content remains unchanged]

### Agent Learning & Optimization
| Date       | Title                                                                 | Venue          | Paper | Code |
|------------|-----------------------------------------------------------------------|----------------|-------|------|
| 2024-04    | Exploring Expert Failures Improves LLM Agent Tuning                   | arXiv          | [Paper](https://arxiv.org/abs/2504.13145) | - |
| 2024-04    | Sleep-time Compute: Beyond Inference Scaling at Test-time             | arXiv          | [Paper](https://arxiv.org/abs/2504.13171) | - |
| 2024-04    | It's All Connected: Test-Time Memorization and Attentional Bias       | arXiv          | [Paper](https://arxiv.org/abs/2504.13173) | - |

### Vision-Language Understanding
| Date       | Title                                                                 | Venue          | Paper | Code |
|------------|-----------------------------------------------------------------------|----------------|-------|------|
| 2024-04    | PerceptionLM: Open-Access Data and Models                             | arXiv          | [Paper](https://arxiv.org/abs/2504.13180) | - |
| 2024-04    | Perception Encoder: Visual Embeddings in Network Layers               | arXiv          | [Paper](https://arxiv.org/abs/2504.13181) | - |
| 2024-04    | Low-hallucination Synthetic Captions for Vision-Language Models       | arXiv          | [Paper](https://arxiv.org/abs/2504.13123) | - |

### Event-based Processing
| Date       | Title                                                                 | Venue          | Paper | Code |
|------------|-----------------------------------------------------------------------|----------------|-------|------|
| 2024-04    | EventVAD: Training-Free Event-Aware Video Anomaly Detection           | arXiv          | [Paper](https://arxiv.org/abs/2504.13092) | - |
| 2024-04    | Novel Demonstration Generation with Gaussian Splatting                | arXiv          | [Paper](https://arxiv.org/abs/2504.13175) | - |

[Rest of the content remains unchanged]
